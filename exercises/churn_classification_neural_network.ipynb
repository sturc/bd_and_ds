{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification via Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from helpers.path_translation import translate_to_file_string\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassificationModel, MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorAssembler, VectorIndexer, StandardScaler\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql import DataFrameReader\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFile = translate_to_file_string(\"../data/churn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a SparkSession\n",
    "spark = (SparkSession\n",
    "       .builder\n",
    "       .appName(\"ChurnClustering\")\n",
    "       .getOrCreate())\n",
    "# create a DataFrame using an ifered Schema \n",
    "df = spark.read.option(\"header\", \"true\") \\\n",
    "       .option(\"inferSchema\", \"true\") \\\n",
    "       .option(\"delimiter\", \";\") \\\n",
    "       .csv(inputFile)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preperation\n",
    "splits = df.randomSplit([0.6, 0.4 ], 1234)\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "   \n",
    "# Transform labels into index\n",
    "labelIndexer = StringIndexer(inputCol=\"LEAVE\", outputCol=\"label\").fit(df)\n",
    "collegeIndexer = StringIndexer().setInputCol(\"COLLEGE\").setOutputCol(\"COLLEGE_NUM\")\n",
    "satIndexer = StringIndexer().setInputCol(\"REPORTED_SATISFACTION\").setOutputCol(\"REPORTED_SATISFACTION_NUM\")\n",
    "usageIndexer = StringIndexer().setInputCol(\"REPORTED_USAGE_LEVEL\").setOutputCol(\"REPORTED_USAGE_LEVEL_NUM\")\n",
    "changeIndexer = StringIndexer().setInputCol(\"CONSIDERING_CHANGE_OF_PLAN\").setOutputCol(\"CONSIDERING_CHANGE_OF_PLAN_NUM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build feature vector\n",
    "featureCols = df.columns.copy()\n",
    "featureCols.remove(\"LEAVE\")\n",
    "featureCols.remove(\"COLLEGE\")\n",
    "featureCols.remove(\"REPORTED_SATISFACTION\")\n",
    "featureCols.remove(\"REPORTED_USAGE_LEVEL\")\n",
    "featureCols.remove(\"CONSIDERING_CHANGE_OF_PLAN\")\n",
    "featureCols = featureCols +[\"COLLEGE_NUM\",\"REPORTED_SATISFACTION_NUM\",\"REPORTED_USAGE_LEVEL_NUM\",\"CONSIDERING_CHANGE_OF_PLAN_NUM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler =  VectorAssembler(outputCol=\"features\", inputCols=list(featureCols))\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=False)\n",
    "predConverter = IndexToString(inputCol=\"prediction\",outputCol=\"predictedLabel\",labels=labelIndexer.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MultilayerPerceptronClassifier(seed=1234, featuresCol=\"scaledFeatures\")\n",
    "   \n",
    "# build network parameters grid\n",
    "# TODO add change the params \n",
    "\n",
    "paramGrid =  ParamGridBuilder().addGrid(nn.layers, [[ 11, 12, 5, 2 ]]) \\\n",
    "\t\t\t\t.addGrid(nn.blockSize,  [128 ]) \\\n",
    "                .addGrid(nn.maxIter,[ 100 ] )\\\n",
    "\t\t\t\t.addGrid(nn.stepSize, [ 0.3 ])\\\n",
    "\t\t\t\t.addGrid(nn.tol, [ 0.05 ]) \\\n",
    "\t\t\t\t.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages= [labelIndexer, collegeIndexer, satIndexer,\n",
    "\t\t\t\tusageIndexer, changeIndexer, assembler, scaler, nn, predConverter ])\n",
    "\n",
    "\n",
    "evaluator =  BinaryClassificationEvaluator(labelCol=\"label\",rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "\n",
    "cv = CrossValidator(estimator=pipeline, evaluator=evaluator,estimatorParamMaps=paramGrid,numFolds=2, parallelism=2)\n",
    "\n",
    "cvModel = cv.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel = cvModel.bestModel.stages[7]\n",
    "print(\"Layers: \" , bestModel.layers)\n",
    "print(bestModel.explainParams())\n",
    "  \n",
    "predictions = cvModel.transform(test)\n",
    "\n",
    "predictions.show()\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = \" ,(1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69547edc0321ee61b18014a62d79d67ae43092e495c103c098ab3bf63b872d9b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5  ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
