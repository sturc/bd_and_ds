{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import sys\n","sys.path.append(\"..\")\n","from pyspark.sql.session import SparkSession\n","from pyspark.ml.classification import LinearSVC, LogisticRegression, OneVsRest\n","from pyspark.ml.feature import StandardScaler, StringIndexer, VectorAssembler\n","from pyspark.ml import Pipeline\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n","from helpers.path_translation import translate_to_file_string"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["inputFile = translate_to_file_string(\"../data/csh101.ann.features.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["main program"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# create a SparkSession\n","spark = SparkSession.builder.appName(\"CasasSVN\").getOrCreate()\n","# create a DataFrame using an ifered Schema\n","df = spark.read.option(\"header\", \"true\") \\\n","        .option(\"inferSchema\", \"true\") \\\n","        .option(\"delimiter\", \",\") \\\n","        .csv(inputFile)\n","# Prepare training and test data.\n","splits = df.randomSplit([0.9, 0.1 ], 12345)\n","training = splits[0]\n","test = splits[1]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["featureCols = df.columns.copy()\n","featureCols.remove(\"activity\") # = label\n","assembler =  VectorAssembler(outputCol=\"features\", inputCols=featureCols)\n","labelIndexer = StringIndexer(inputCol=\"activity\", outputCol=\"label\")\n","scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n","                        withStd=True, withMean=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#  # build network parameters grid\n","# paramGrid = ParamGridBuilder().addGrid(lr.maxIter, [100 ])\\\n","#                              .addGrid(lr.regParam, [0.001]) \\\n","#                              .build()\n","   \n","lsvc = LinearSVC(labelCol=\"label\",aggregationDepth=2, featuresCol=\"scaledFeatures\")\n","paramGrid = ParamGridBuilder().addGrid(lsvc.maxIter, [100 ])\\\n","                                 .addGrid(lsvc.regParam, [0.1]) \\\n","                                 .build()\n","\n","# the One Vs Rest Classifier.\n","ovr = OneVsRest(classifier=lsvc)\n","\n","# Build the pipeline\n","pipeline = Pipeline(stages= [assembler, labelIndexer, scaler, ovr] )\n","evaluator = MulticlassClassificationEvaluator(\n","labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n","cv = CrossValidator(estimator=pipeline, evaluator=evaluator,estimatorParamMaps=paramGrid,numFolds=2, parallelism=2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#fit (train) the model\n","cvModel = cv.fit(training)\n","\t\t\n","#test the model\n","predictions = cvModel.transform(test)\n","accuracy = evaluator.evaluate(predictions)\n","print(\"Test Error = %g\" % (1.0 - accuracy))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["spark.stop()"]}],"metadata":{"interpreter":{"hash":"69547edc0321ee61b18014a62d79d67ae43092e495c103c098ab3bf63b872d9b"},"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"}},"nbformat":4,"nbformat_minor":2}
