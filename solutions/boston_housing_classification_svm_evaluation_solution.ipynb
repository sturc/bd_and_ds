{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston Housing Classification SVM Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql.functions import expr,col\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.types import BooleanType\n",
    "from helpers.path_translation import translate_to_file_string\n",
    "from helpers.data_prep_and_print import print_df, add_weight_col, print_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFile = translate_to_file_string(\"../data/Boston_Housing_Data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark session creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "       .builder\n",
    "       .appName(\"BostonHousingSVNEval\")\n",
    "       .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame creation using an ifered Schema "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"header\", \"true\") \\\n",
    "       .option(\"inferSchema\", \"true\") \\\n",
    "       .option(\"delimiter\", \";\") \\\n",
    "       .csv(inputFile) \\\n",
    "       .withColumn(\"CATBOOL\", expr(\"CAT\").cast(BooleanType()))\n",
    "print(df.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df = add_weight_col(df,\"CAT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = balanced_df.randomSplit([0.9, 0.1 ], 12345)\n",
    "training = splits[0]\n",
    "test = splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureCols = df.columns.copy()\n",
    "featureCols.remove(\"MEDV\")\n",
    "featureCols.remove(\"CAT\")\n",
    "featureCols.remove(\"CATBOOL\") \n",
    "print(featureCols)\n",
    "\n",
    "assembler =  VectorAssembler(outputCol=\"features\", inputCols=featureCols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol=\"CAT\",rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\",weightCol=\"classWeightCol\")\n",
    "#evaluator = MulticlassClassificationEvaluator(labelCol=\"CAT\", predictionCol=\"prediction\", metricName='weightedPrecision', weightCol=\"classWeightCol\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc = LinearSVC(labelCol=\"CAT\",aggregationDepth=2, featuresCol=\"features\" ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages= [assembler, lsvc] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the paramGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder().addGrid(lsvc.maxIter, [100])\\\n",
    "                                 .addGrid(lsvc.regParam, [0.1, 0.001, 0.0001]) \\\n",
    "                                 .addGrid(lsvc.standardization, [True, False]) \\\n",
    "                                 .build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the CrossValidator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvSVM = CrossValidator(estimator=pipeline, evaluator=evaluator, \\\n",
    "                          estimatorParamMaps=paramGrid, numFolds=5, parallelism=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvSVMModel = cvSVM.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show best Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearSVCModel = cvSVMModel.bestModel.stages[1] # the stage at index 1 in the pipeline is the SVMModel\n",
    "print(\"Best Params: \\n\", linearSVCModel.explainParams())\n",
    "print(\"Param Map: \\n\", linearSVCModel.extractParamMap())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cvSVMModel.transform(test)\n",
    "print_df(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Model\n",
    "## Area under ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error\",(1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionAndLabels = predictions.select(\"prediction\", \"CAT\").rdd.map(lambda p: [p[0], float(p[1])]) # Map to RDD prediction|label\n",
    "metrics =  MulticlassMetrics(predictionAndLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = metrics.confusionMatrix()\n",
    "print_confusion_matrix(spark, confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the confusion matrix\n",
    "print_df (predictions.select(\"prediction\", \"CAT\"))\n",
    "print(\"True Positives (Pred. = 0 & Label = 0) %f \" % predictions.filter(predictions.prediction==predictions.CAT).filter(predictions.CAT == 0).count())\n",
    "print(\"True Negatives (Pred. = 1 & Label = 1) %f \" % predictions.filter(predictions.prediction==predictions.CAT).filter(predictions.CAT == 1).count())\n",
    "print(\"False Positives (Pred. = 0 & Label = 1) %f \" % predictions.filter(predictions.prediction!=predictions.CAT).filter(predictions.CAT == 1).count())\n",
    "print(\"False Negatives (Pred = 0 & Label = 0) %f \" % predictions.filter(predictions.prediction!=predictions.CAT).filter(predictions.CAT == 0).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics per label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = predictionAndLabels.map(lambda x: x[1]).distinct().collect()\n",
    "print(labels)\n",
    "for label in  labels:\n",
    "  print(\"Class %f precision = %f\\n\" % (label , metrics.precision(label)))\n",
    "  print(\"Class %f recall = %f\\n\" % (label, metrics.recall(label)))\n",
    "  print(\"Class %f F1 score = %f\\n\" % (label, metrics.fMeasure( label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Weighted precision = %s\\n\" % metrics.weightedPrecision)\n",
    "print(\"Weighted recall = %s\\n\" % metrics.weightedRecall)\n",
    "print(\"Weighted false positive rate = %s\\n\" % metrics.weightedFalsePositiveRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Summary stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Recall = {metrics.recall(1.0)}\")\n",
    "print(f\"Precision = {metrics.precision(1.0)}\")\n",
    "print(f\"Accuracy = {metrics.accuracy}\") \n",
    "print(f\"F1 = {metrics.fMeasure(1.0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d2589c10bdcbd078b7043d35b956b9364f4d9a37ceb87d8e3e029d304f5a6f7"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
