{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn Dataset Correlation Calculation in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from helpers.data_prep_and_print import print_df\n",
    "from helpers.path_translation import translate_to_file_string\n",
    "from pyspark.ml.feature import IndexToString, Normalizer, StringIndexer, VectorAssembler, VectorIndexer\n",
    "from pyspark.ml.stat import Correlation, ChiSquareTest\n",
    "\n",
    "from pyspark.sql import DataFrameReader\n",
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the churn file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFile = translate_to_file_string(\"../data/churn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Spark Session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a SparkSession\n",
    "spark = (SparkSession\n",
    "       .builder\n",
    "       .appName(\"Churn Proprocessing\")\n",
    "       .getOrCreate())\n",
    "# create a DataFrame using an ifered Schema \n",
    "df = spark.read.option(\"header\", \"true\") \\\n",
    "       .option(\"inferSchema\", \"true\") \\\n",
    "       .option(\"delimiter\", \";\") \\\n",
    "       .csv(inputFile)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "### Transform labels into index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelIndexer = StringIndexer().setInputCol(\"LEAVE\").setOutputCol(\"label\").fit(df)\n",
    "collegeIndexer = StringIndexer().setInputCol(\"COLLEGE\").setOutputCol(\"COLLEGE_NUM\").fit(df)\n",
    "satIndexer = StringIndexer().setInputCol(\"REPORTED_SATISFACTION\").setOutputCol(\"REPORTED_SATISFACTION_NUM\").fit(df)\n",
    "usageIndexer = StringIndexer().setInputCol(\"REPORTED_USAGE_LEVEL\").setOutputCol(\"REPORTED_USAGE_LEVEL_NUM\").fit(df)\n",
    "changeIndexer = StringIndexer().setInputCol(\"CONSIDERING_CHANGE_OF_PLAN\").setOutputCol(\"CONSIDERING_CHANGE_OF_PLAN_NUM\").fit(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Build the feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureCols = df.columns.copy()\n",
    "featureCols.remove(\"LEAVE\")\n",
    "featureCols.remove(\"COLLEGE\")\n",
    "featureCols.remove(\"REPORTED_SATISFACTION\")\n",
    "featureCols.remove(\"REPORTED_USAGE_LEVEL\")\n",
    "featureCols.remove(\"CONSIDERING_CHANGE_OF_PLAN\")\n",
    "featureCols = featureCols +[\"COLLEGE_NUM\",\"REPORTED_SATISFACTION_NUM\",\"REPORTED_USAGE_LEVEL_NUM\",\"CONSIDERING_CHANGE_OF_PLAN_NUM\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the feature Vector Assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler =  VectorAssembler(outputCol=\"features\", inputCols=list(featureCols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeledData = labelIndexer.transform(df)\n",
    "print(labeledData.printSchema())\n",
    "indexedLabedData = collegeIndexer.transform(satIndexer.transform(usageIndexer.transform(changeIndexer.transform(labeledData))))\n",
    "labeledPointData = assembler.transform(indexedLabedData)\n",
    "labeledPointData.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As formated output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_df(labeledPointData.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1_matrix = Correlation.corr(labeledPointData, \"features\").collect()[0][0]\n",
    "corr_matrix = r1_matrix.toArray().tolist()\n",
    "df_corr_matrix = spark.createDataFrame(corr_matrix,featureCols)\n",
    "\n",
    "print_df(df_corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r = ChiSquareTest.test(labeledPointData, \"features\", \"label\").head()\n",
    "#print(\"pValues: \" + str(r.pValues))\n",
    "#print(\"degreesOfFreedom: \" + str(r.degreesOfFreedom))\n",
    "#print(\"statistics: \" + str(r.statistics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
