{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Boston Housing KNN"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[],"source":["from pyspark.sql.types import BooleanType\n","from pyspark.ml.feature import StringIndexer, VectorAssembler, BucketedRandomProjectionLSH, MinHashLSH\n","from pyspark.ml.classification import LinearSVC\n","from pyspark.sql.session import SparkSession, Row\n","from pyspark.sql.functions import desc, expr\n","from pyspark.ml.evaluation import BinaryClassificationEvaluator\n"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[],"source":["inputFile = \"../data/Boston_Housing_Data.csv\""]},{"cell_type":"markdown","metadata":{},"source":["Spark session creation "]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[],"source":["spark = (SparkSession\n","       .builder\n","       .appName(\"ChurnDataPreprocessing\")\n","       .getOrCreate())"]},{"cell_type":"markdown","metadata":{},"source":["DataFrame creation using an ifered Schema "]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":"root\n |-- CRIM: double (nullable = true)\n |-- ZN: double (nullable = true)\n |-- INDUS: double (nullable = true)\n |-- CHAS: integer (nullable = true)\n |-- NOX: double (nullable = true)\n |-- RM: double (nullable = true)\n |-- AGE: double (nullable = true)\n |-- DIS: double (nullable = true)\n |-- RAD: integer (nullable = true)\n |-- TAX: integer (nullable = true)\n |-- PTRATIO: double (nullable = true)\n |-- B: double (nullable = true)\n |-- LSTAT: double (nullable = true)\n |-- MEDV: double (nullable = true)\n |-- CAT: integer (nullable = true)\n |-- CATBOOL: boolean (nullable = true)\n\nNone\n"}],"source":["df = spark.read.option(\"header\", \"true\") \\\n","       .option(\"inferSchema\", \"true\") \\\n","       .option(\"delimiter\", \";\") \\\n","       .csv(inputFile) \\\n","       .withColumn(\"CATBOOL\", expr(\"CAT\").cast(BooleanType()))\n","print(df.printSchema())"]},{"cell_type":"markdown","metadata":{},"source":["Prepare training and test data."]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":"['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n"}],"source":["featureCols = df.columns.copy()\n","featureCols.remove(\"MEDV\")\n","featureCols.remove(\"CAT\")\n","featureCols.remove(\"CATBOOL\") \n","print(featureCols)\n","\n","assembler =  VectorAssembler(outputCol=\"features\", inputCols=featureCols)"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[],"source":["labledPointDataSet = assembler.transform(df)\n","splits = labledPointDataSet.randomSplit([0.9, 0.1 ], 12345)\n","training = splits[0]\n","test = splits[1]"]},{"cell_type":"markdown","metadata":{},"source":["LHS Euclidean Distance"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[],"source":["lhsED = BucketedRandomProjectionLSH(inputCol=\"features\", outputCol=\"hashes\", bucketLength =2.0, numHashTables=3)"]},{"cell_type":"markdown","metadata":{},"source":["Train the model "]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[],"source":["modelED = lhsED.fit(training)"]},{"cell_type":"markdown","metadata":{},"source":["Test the model"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":"+---+--------------------+----------+\n|CAT|            features|prediction|\n+---+--------------------+----------+\n|  1|[0.01311,90.0,1.2...|       1.0|\n|  0|[0.01439,60.0,2.9...|       1.0|\n|  0|[0.03871,52.5,5.3...|       0.0|\n|  0|[0.0456,0.0,13.89...|       0.0|\n|  0|[0.04932,33.0,2.1...|       1.0|\n|  0|[0.05023,35.0,6.0...|       0.0|\n|  0|[0.05372,0.0,13.9...|       0.0|\n|  0|[0.06417,0.0,5.96...|       0.0|\n|  0|[0.06466,70.0,2.2...|       0.0|\n|  0|[0.06617,0.0,3.24...|       0.0|\n|  0|[0.08244,30.0,4.9...|       0.0|\n|  0|[0.09849,0.0,25.6...|       0.0|\n|  1|[0.1,34.0,6.09,0....|       0.0|\n|  0|[0.10153,0.0,12.8...|       0.0|\n|  0|[0.11504,0.0,2.89...|       0.0|\n|  0|[0.11747,12.5,7.8...|       0.0|\n|  0|[0.14455,12.5,7.8...|       0.0|\n|  0|[0.15038,0.0,25.6...|       0.0|\n|  0|[0.17004,12.5,7.8...|       0.0|\n|  0|[0.19186,0.0,7.38...|       0.0|\n+---+--------------------+----------+\nonly showing top 20 rows\n\n"}],"source":["resultList = []\n","# The Nearest neighbor testing\n","for row in test.collect() :\n","     neighbors = modelED.approxNearestNeighbors(training, row.features, 5)\n","     grouped = neighbors.groupBy(df.CAT).count()\n","     result = grouped.orderBy(desc(\"count\")).first().CAT\n","     newRow = Row(CAT=row.CAT, features=row.features, prediction=float (result))\n","     resultList.append(newRow)\t\n","\n","predictions = spark.createDataFrame(resultList)\n","predictions.createOrReplaceTempView(\"resultList\")\n","predictions.show()"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":"Test Error 0.2455357142857143\n"}],"source":["evaluator = BinaryClassificationEvaluator(labelCol=\"CAT\",rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")\n","accuracy = evaluator.evaluate(predictions)\n","print(\"Test Error\",(1.0 - accuracy))"]}],"metadata":{"kernelspec":{"display_name":"venv","language":"python","name":"venv"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5-final"}},"nbformat":4,"nbformat_minor":2}